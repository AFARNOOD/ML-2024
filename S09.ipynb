{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc9d8cc4-5f14-4b67-824e-2a457c14dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21e4015e-e69a-4dbf-a6f9-8b40254275d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5400437-a60f-4b4f-86a0-2f308b950b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model_2024_hairstyle.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68d01b22-76b1-4f3f-8256-8433896d6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "with open(model_path, \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7ad012-5663-45b4-8615-82154f85bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Model downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6847c3af-90f8-4537-a519-dfddc55a348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58d19c3c-d313-4792-9733-5fad9aadfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.models.load_model(\"model_2024_hairstyle.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3787539-937b-4a43-abd2-2c020a4a1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e18723f-a4d5-4954-a044-45ba60c37f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\a_farnoo\\AppData\\Local\\Temp\\tmpn23imw5t\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\a_farnoo\\AppData\\Local\\Temp\\tmpn23imw5t\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\a_farnoo\\AppData\\Local\\Temp\\tmpn23imw5t'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2185894123024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2185894123408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2185894123600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2185894124560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2185894124752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2185894125328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aee94ce8-ea79-4fb4-b699-fbc6f2533a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_path = \"model_2024_hairstyle.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "991879f1-0a2f-401b-8bd0-7faaf9629ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11568a08-9cbb-41cf-95de-cf4299200f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully converted to TF-Lite!\n"
     ]
    }
   ],
   "source": [
    "print(\"Model successfully converted to TF-Lite!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea606ab4-ef0a-43d4-ab9a-96a8f568718a",
   "metadata": {},
   "source": [
    "# Q.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fa893b2-ef04-4ae1-9a86-a3224b1cebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e747f437-5218-43e3-a529-6b4281d9f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the TF-Lite model: 76.58 MB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(tflite_model_path) / (1024 * 1024)\n",
    "print(f\"Size of the TF-Lite model: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a088f71-b44f-45c9-92e2-a1a25572fe7c",
   "metadata": {},
   "source": [
    "# Q.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c18e187-b32d-4914-b183-978907e11e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "417780dc-6037-4702-afea-eaaadbc2f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d462a9aa-33c8-44bc-926f-38d4cac7bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'shape_signature': array([ -1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output index: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)\n",
    "print(\"Output index:\", output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9b53c-40f4-41ec-a2a5-534d4e3308c4",
   "metadata": {},
   "source": [
    "# Q.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20ee5a04-45e1-405f-a2d6-227a14654c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\a_farnoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\a_farnoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dfcd40f-d155-4754-bd92-2e89ce69c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d582ac3d-57c8-4ddd-b7a3-657127892f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5f9f8b0-a72e-48cb-9421-ca07756f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99c66006-bade-4b95-9e71-afd4681789fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and resize the image\n",
    "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "target_size = (150, 150)  # Target size from the previous homework\n",
    "img = download_image(url)\n",
    "img_resized = prepare_image(img, target_size)\n",
    "img_resized.show()  # This will display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eec0f458-ab48-4449-9ea8-e7b3d1f86052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c215c343-2a08-43ea-913f-cd2c0d4bb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array(img_resized, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63896a59-6543-48ee-b0d4-93b901bbce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "728dd787-6b78-4b4d-93fc-9ee7bba618e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c6c0b9d-1c69-4237-ac07-f52d4deb9190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value in the first pixel, R channel: 0.26\n"
     ]
    }
   ],
   "source": [
    "first_pixel_r = img_array[0, 0, 0, 0]  # R channel of the first pixel\n",
    "print(f\"Value in the first pixel, R channel: {first_pixel_r:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aae91e-bca6-4a9e-9009-2474488581f4",
   "metadata": {},
   "source": [
    "# Q.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "301ba999-3a9d-44df-be02-c8b7bb0a3183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c4e6e8f-e5dc-4a52-8cfa-bdf26a047c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"model_2024_hairstyle.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d0846ca-d338-4843-b779-3a50fa2b5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "feeaf3ef-2aae-4aa1-9ae8-7a016a44cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = input_details[0]['index']\n",
    "output_index = output_details[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0e014eb-9d2e-4155-854a-54f5c43a852d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 150 but expected 200 for dimension 1 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:744\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[0;32m    729\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \n\u001b[0;32m    731\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 150 but expected 200 for dimension 1 of input 0."
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "efd1cdc4-2052-40d7-8d4b-83012d70a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4130bdc-6419-498f-8ee1-95c687e62f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the model: 0.453\n"
     ]
    }
   ],
   "source": [
    "output = interpreter.get_tensor(output_index)[0][0]\n",
    "print(f\"Output of the model: {output:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa48ea-e680-4ce2-932a-36dd186e360e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
